# from typing import List, Dict, Optional
# from app.models import CardType
# import random

# class ExtractionService:
#     """
#     Service for extracting cards from meeting transcripts.
    
#     Currently uses placeholder logic. Will be replaced with actual LLM calls.
#     """
    
#     def extract_cards(
#         self,
#         transcript: str,
#         agenda_items: Optional[List[str]],
#         requested_types: List[CardType]
#     ) -> List[Dict]:
#         """
#         Extract cards from transcript based on requested types.
        
#         Args:
#             transcript: The meeting transcript text
#             agenda_items: Optional list of agenda items
#             requested_types: Types of cards to extract
            
#         Returns:
#             List of card data dictionaries
#         """
#         # PLACEHOLDER: This will be replaced with actual LLM extraction
#         # For now, generate some sample cards based on requested types
        
#         cards = []
#         position_offset = 0
        
#         for card_type in requested_types:
#             card = self._generate_placeholder_card(
#                 card_type,
#                 transcript,
#                 position_offset
#             )
#             if card:
#                 cards.append(card)
#                 position_offset += 1
        
#         return cards
    
#     def _generate_placeholder_card(
#         self,
#         card_type: CardType,
#         transcript: str,
#         position_index: int
#     ) -> Dict:
#         """Generate a placeholder card (to be replaced with LLM extraction)"""
        
#         # Extract a snippet from transcript for demonstration
#         words = transcript.split()
#         snippet_length = min(50, len(words))
#         snippet = " ".join(words[:snippet_length])
#         if len(words) > snippet_length:
#             snippet += "..."
        
#         templates = {
#             CardType.TLDR: {
#                 "title": "Meeting Summary",
#                 "content": f"TL;DR: This is a placeholder summary that will be generated by LLM. Based on: {snippet}"
#             },
#             CardType.TODO: {
#                 "title": "Action Items",
#                 "content": "TODO: Items will be extracted from transcript using LLM"
#             },
#             CardType.ACTION_ITEM: {
#                 "title": "Action Item",
#                 "content": "Specific action item extracted from meeting (placeholder)"
#             },
#             CardType.DECISION: {
#                 "title": "Decision Made",
#                 "content": "Key decisions from the meeting (placeholder)"
#             },
#             CardType.QUESTION: {
#                 "title": "Open Question",
#                 "content": "Questions raised during meeting (placeholder)"
#             },
#             CardType.DISCUSSION_POINT: {
#                 "title": "Discussion Point",
#                 "content": "Important discussion topic (placeholder)"
#             },
#             CardType.FOLLOW_UP: {
#                 "title": "Follow-up Required",
#                 "content": "Items requiring follow-up (placeholder)"
#             }
#         }
        
#         if card_type not in templates:
#             return None
        
#         template = templates[card_type]
        
#         return {
#             "type": card_type,
#             "title": template["title"],
#             "content": template["content"],
#             "segment": snippet,
#             "position_x": (position_index % 3) * 300,  # Arrange in grid
#             "position_y": (position_index // 3) * 200
#         }
    
#     def find_uncovered_agenda_items(
#         self,
#         agenda_items: List[str],
#         transcript: str
#     ) -> List[str]:
#         """
#         Find agenda items that were not covered in the meeting.
        
#         Args:
#             agenda_items: List of planned agenda items
#             transcript: The meeting transcript
            
#         Returns:
#             List of uncovered agenda items
#         """
#         # PLACEHOLDER: Will use LLM to match agenda items to transcript
#         # For now, do simple keyword matching
        
#         uncovered = []
#         transcript_lower = transcript.lower()
        
#         for item in agenda_items:
#             # Simple check: if none of the words in agenda item appear in transcript
#             item_words = item.lower().split()
#             if not any(word in transcript_lower for word in item_words if len(word) > 3):
#                 uncovered.append(item)
        
#         return uncovered
    
#     def extract_segment_for_card(
#         self,
#         transcript: str,
#         card_content: str
#     ) -> Optional[str]:
#         """
#         Find the relevant transcript segment for a card.
        
#         Args:
#             transcript: Full meeting transcript
#             card_content: Content of the card
            
#         Returns:
#             Relevant transcript segment or None
#         """
#         # PLACEHOLDER: Will use LLM to find relevant segments
#         # For now, return None
#         return None

import sys
sys.path.append('/Users/zinnianie/Desktop/ScholarSidekick')

from typing import List, Dict, Optional
from app.models import CardType
from google import genai
from google.genai.types import Schema, Type
import json


class ExtractionService:
    """
    Service for extracting cards from meeting transcripts using Google Gemini.
    """

    def __init__(self, api_key: str):
        self.model = genai.Client(api_key=api_key)

    # ----------------------------------------------------
    # MAIN CARD EXTRACTION
    # ----------------------------------------------------
    def extract_cards(
        self,
        transcript: str,
        agenda_items: Optional[List[str]],
        requested_types: List[CardType],
    ) -> List[Dict]:

        type_instructions = "\n".join(f"- {ct.value}" for ct in requested_types)

        agenda_section = (
            "\nAgenda Items:\n" + "\n".join(f"- {a}" for a in agenda_items)
            if agenda_items else ""
        )

        prompt = f"""
You are an AI assistant that extracts structured information from meeting transcripts.

Extract the following card types from the transcript:
{type_instructions}

For each extracted card, return JSON objects with keys:
- type: card type
- title: short descriptive title
- content: key information
- segment: exact snippet from the transcript that supports it

If the card type is 'tldr', leave the segment section empty.

Transcript:
\"\"\"{transcript}\"\"\"
{agenda_section}

Return ONLY valid JSON array.
"""

        response_text = self._call_llm(prompt)

        try:
            cards = json.loads(response_text)
        except Exception:
            cards = []

        # Add layout metadata
        for i, card in enumerate(cards):
            card["position_x"] = (i % 3) * 300
            card["position_y"] = (i // 3) * 200

        return cards

    # ----------------------------------------------------
    # AGENDA MATCHING
    # ----------------------------------------------------
    def find_uncovered_agenda_items(
        self,
        agenda_items: List[str],
        transcript: str
    ) -> List[str]:

        prompt = f"""
Identify which agenda items were NOT covered in the meeting.

Agenda:
{json.dumps(agenda_items)}

Transcript:
\"\"\"{transcript}\"\"\"

Return ONLY a JSON array of uncovered agenda item strings.
"""

        response_text = self._call_llm(prompt)

        try:
            return json.loads(response_text)
        except Exception:
            return []

    # ----------------------------------------------------
    # SEGMENT EXTRACTION
    # ----------------------------------------------------
    def extract_segment_for_card(
        self,
        transcript: str,
        card_content: str
    ) -> Optional[str]:

        prompt = f"""
Find the exact snippet in the transcript that supports the following card content:

Card Content:
\"\"\"{card_content}\"\"\"

Transcript:
\"\"\"{transcript}\"\"\"

Return ONLY a JSON string containing the matching snippet, or null if none found.
"""

        response_text = self._call_llm(prompt)

        try:
            return json.loads(response_text)
        except Exception:
            return None

    # ----------------------------------------------------
    # INTERNAL GEMINI CALL
    # ----------------------------------------------------

    # Define the expected output structure as a Schema
    # This schema applies to the extract_cards method's output.
    # You will need to define a separate schema for each method's expected output.
    CARD_ARRAY_SCHEMA = Schema(
        type=Type.ARRAY,
        description="An array of extracted cards.",
        items=Schema(
            type=Type.OBJECT,
            properties={
                "type": Schema(type=Type.STRING, description="card type"),
                "title": Schema(type=Type.STRING, description="short descriptive title"),
                "content": Schema(type=Type.STRING, description="key information"),
                "segment": Schema(type=Type.STRING, description="exact snippet from the transcript that supports it"),
            },
            required=["type", "title", "content", "segment"],
        )
    )

    def _call_llm(self, prompt: str) -> str:
        """
        Gemini relies on .generate_content() and responses may contain
        text parts or JSON; we extract plain text.
        """

        response = self.model.models.generate_content(
            model="gemini-2.5-flash",
            contents=prompt,
            config=genai.types.GenerateContentConfig(
                # Crucial for structured output:
                response_mime_type="application/json", 
                response_schema=self.CARD_ARRAY_SCHEMA 
            )
        )

        # response.text will now safely contain ONLY the guaranteed JSON string.
        # The internal metadata like 'thought_signature' will be handled correctly.
        return response.text
